{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f79baf9",
   "metadata": {},
   "source": [
    "# ADS 509 Sentiment Assignment\n",
    "\n",
    "This notebook holds the Sentiment Assignment for Module 6 in ADS 509, Applied Text Mining. Work through this notebook, writing code and answering questions where required. \n",
    "\n",
    "In a previous assignment you put together Twitter data and lyrics data on two artists. In this assignment we apply sentiment analysis to those data sets. If, for some reason, you did not complete that previous assignment, data to use for this assignment can be found in the assignment materials section of Blackboard. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae8e2e1",
   "metadata": {},
   "source": [
    "## General Assignment Instructions\n",
    "\n",
    "These instructions are included in every assignment, to remind you of the coding standards for the class. Feel free to delete this cell after reading it. \n",
    "\n",
    "One sign of mature code is conforming to a style guide. We recommend the [Google Python Style Guide](https://google.github.io/styleguide/pyguide.html). If you use a different style guide, please include a cell with a link. \n",
    "\n",
    "Your code should be relatively easy-to-read, sensibly commented, and clean. Writing code is a messy process, so please be sure to edit your final submission. Remove any cells that are not needed or parts of cells that contain unnecessary code. Remove inessential `import` statements and make sure that all such statements are moved into the designated cell. \n",
    "\n",
    "Make use of non-code cells for written commentary. These cells should be grammatical and clearly written. In some of these cells you will have questions to answer. The questions will be marked by a \"Q:\" and will have a corresponding \"A:\" spot for you. *Make sure to answer every question marked with a `Q:` for full credit.* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2d096b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import emoji\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b555ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add any additional import statements you need here\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "923b5a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change `data_location` to the location of the folder on your machine.\n",
    "data_location = \"/Users/kyledalope/Documents/GitHub/ads509-tm-sentiment\"\n",
    "\n",
    "# These subfolders should still work if you correctly stored the \n",
    "# data from the Module 1 assignment\n",
    "twitter_folder = \"/Users/kyledalope/Downloads/M1 Results/twitter\"\n",
    "lyrics_folder = \"/Users/kyledalope/Downloads/M1 Results/lyrics\"\n",
    "\n",
    "positive_words_file = \"positive-words.txt\"\n",
    "negative_words_file = \"negative-words.txt\"\n",
    "tidy_text_file = \"tidytext_sentiments.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3bf93e",
   "metadata": {},
   "source": [
    "## Data Input\n",
    "\n",
    "Now read in each of the corpora. For the lyrics data, it may be convenient to store the entire contents of the file to make it easier to inspect the titles individually, as you'll do in the last part of the assignment. In the solution, I stored the lyrics data in a dictionary with two dimensions of keys: artist and song. The value was the file contents. A Pandas data frame would work equally well. \n",
    "\n",
    "For the Twitter data, we only need the description field for this assignment. Feel free all the descriptions read it into a data structure. In the solution, I stored the descriptions as a dictionary of lists, with the key being the artist. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37d70801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the lyrics data\n",
    "\n",
    "lyrics = {}\n",
    "# For loop to the artist subfolders\n",
    "for artist_sub in os.listdir(lyrics_folder):\n",
    "    artist_path = os.path.join(lyrics_folder, artist_sub)\n",
    "    if os.path.isdir(artist_path):\n",
    "        lyrics[artist_sub] = {}\n",
    "        \n",
    "        # For loop to the songs for each artist subfolder\n",
    "        for song in os.listdir(artist_path):\n",
    "            song_path = os.path.join(artist_path, song)\n",
    "            if os.path.isfile(song_path):\n",
    "                with open(song_path, 'r') as file:\n",
    "                    lyrics_content = file.read()\n",
    "                    lyrics[artist_sub][song] = lyrics_content\n",
    "\n",
    "# Create a dataframe from the lyrics dictionary\n",
    "lyrics_data = pd.DataFrame([(artist, song, lyrics[artist][song]) for artist in lyrics for song in lyrics[artist]],\n",
    "columns=['artist', 'song', 'lyrics_content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "debcac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the twitter data\n",
    "\n",
    "twitter_descriptions = {}\n",
    "\n",
    "for file_name in os.listdir(twitter_folder):\n",
    "    if file_name.endswith(\".txt\"):\n",
    "        artist = os.path.splitext(file_name)[0]\n",
    "        file_path = os.path.join(twitter_folder, file_name)\n",
    "        with open(file_path, 'r') as file:\n",
    "            descriptions = [line.strip() for line in file]\n",
    "        twitter_descriptions[artist] = descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "af9e7a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the positive and negative words and the\n",
    "# tidytext sentiment. Store these so that the positive\n",
    "# words are associated with a score of +1 and negative words\n",
    "# are associated with a score of -1. You can use a dataframe or a \n",
    "# dictionary for this.\n",
    "\n",
    "# Read positive words\n",
    "positive_words_path = os.path.join(data_location, positive_words_file)\n",
    "positive_words = []\n",
    "with open(positive_words_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\";\"):  # Skip comment lines\n",
    "            positive_words.append(line.strip())\n",
    "\n",
    "# Read negative words\n",
    "negative_words_path = os.path.join(data_location, negative_words_file)\n",
    "negative_words = []\n",
    "with open(negative_words_path, \"r\") as file:\n",
    "    for line in file:\n",
    "        if not line.startswith(\";\"):  # Skip comment lines\n",
    "            negative_words.append(line.strip())\n",
    "\n",
    "# Create dictionaries with scores\n",
    "positive_dict = {word: 1 for word in positive_words}\n",
    "negative_dict = {word: -1 for word in negative_words}\n",
    "\n",
    "# Read tidy text sentiments\n",
    "tidy_text_path = os.path.join(data_location, tidy_text_file)\n",
    "tidy_text_sentiments = pd.read_csv(tidy_text_path, sep=\"\\t\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5f3b12",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Songs\n",
    "\n",
    "In this section, score the sentiment for all the songs for both artists in your data set. Score the sentiment by manually calculating the sentiment using the combined lexicons provided in this repository. \n",
    "\n",
    "After you have calculated these sentiments, answer the questions at the end of this section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "73f82a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_includemeout.txt</td>\n",
       "      <td>\"Include Me Out\"\\n\\n\\n\\nIt is really very simp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_electric.txt</td>\n",
       "      <td>\"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_beach2k20.txt</td>\n",
       "      <td>\"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_lovekills.txt</td>\n",
       "      <td>\"Love Kills\"\\n\\n\\n\\nIf you're looking for love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>robyn</td>\n",
       "      <td>robyn_timemachine.txt</td>\n",
       "      <td>\"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_takeitfromtheboys.txt</td>\n",
       "      <td>\"Take It From The Boys\"\\n\\n\\n\\nSo scared I nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_dreambaby.txt</td>\n",
       "      <td>\"Dream Baby\"\\n\\n\\n\\nI found the boy for me\\nHe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_pleasedonttellme.txt</td>\n",
       "      <td>\"Please Don't Tell Me\"\\n\\n\\n\\nYa shook the ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_ihopeyoufindit.txt</td>\n",
       "      <td>\"I Hope You Find It\"\\n\\n\\n\\nThese clouds aren'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>cher</td>\n",
       "      <td>cher_classified1a.txt</td>\n",
       "      <td>\"Classified 1A\"\\n\\n\\n\\nI know now how much I l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    artist                        song  \\\n",
       "0    robyn      robyn_includemeout.txt   \n",
       "1    robyn          robyn_electric.txt   \n",
       "2    robyn         robyn_beach2k20.txt   \n",
       "3    robyn         robyn_lovekills.txt   \n",
       "4    robyn       robyn_timemachine.txt   \n",
       "..     ...                         ...   \n",
       "415   cher  cher_takeitfromtheboys.txt   \n",
       "416   cher          cher_dreambaby.txt   \n",
       "417   cher   cher_pleasedonttellme.txt   \n",
       "418   cher     cher_ihopeyoufindit.txt   \n",
       "419   cher       cher_classified1a.txt   \n",
       "\n",
       "                                        lyrics_content  \n",
       "0    \"Include Me Out\"\\n\\n\\n\\nIt is really very simp...  \n",
       "1    \"Electric\"\\n\\n\\n\\nElectric...\\n\\nIt's electric...  \n",
       "2    \"Beach 2K20\"\\n\\n\\n\\n(So you wanna go out?\\nHow...  \n",
       "3    \"Love Kills\"\\n\\n\\n\\nIf you're looking for love...  \n",
       "4    \"Time Machine\"\\n\\n\\n\\nHey, what did I do?\\nCan...  \n",
       "..                                                 ...  \n",
       "415  \"Take It From The Boys\"\\n\\n\\n\\nSo scared I nev...  \n",
       "416  \"Dream Baby\"\\n\\n\\n\\nI found the boy for me\\nHe...  \n",
       "417  \"Please Don't Tell Me\"\\n\\n\\n\\nYa shook the ove...  \n",
       "418  \"I Hope You Find It\"\\n\\n\\n\\nThese clouds aren'...  \n",
       "419  \"Classified 1A\"\\n\\n\\n\\nI know now how much I l...  \n",
       "\n",
       "[420 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data #view format of lyrics data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "664f8d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary for song sentiment scores\n",
    "\n",
    "songs_sentiment_scores = []\n",
    "for lyrics_content in lyrics_data['lyrics_content']:\n",
    "    sentiment_score = 0\n",
    "    words = lyrics_content.split()  # Split the lyrics content into words\n",
    "    for word in words:\n",
    "        if word in positive_dict:\n",
    "            sentiment_score += positive_dict[word]\n",
    "        elif word in negative_dict:\n",
    "            sentiment_score += negative_dict[word]\n",
    "    songs_sentiment_scores.append(sentiment_score)\n",
    "\n",
    "# Add sentiment scores to the lyrics data dataframe\n",
    "lyrics_data['SentimentScore'] = songs_sentiment_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9695c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      -8\n",
       "1      -9\n",
       "2      20\n",
       "3     -19\n",
       "4      -3\n",
       "       ..\n",
       "415    10\n",
       "416    11\n",
       "417    -1\n",
       "418    -1\n",
       "419     2\n",
       "Name: SentimentScore, Length: 420, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lyrics_data['SentimentScore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1060a1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist\n",
       "cher     2.177215\n",
       "robyn    0.875000\n",
       "Name: SentimentScore, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average sentiment per song for each artist\n",
    "avg_sent_per_song = lyrics_data.groupby('artist')['SentimentScore'].mean()\n",
    "\n",
    "avg_sent_per_song #view avg sentiment score for cher and robyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1017ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Three highest sentiment songs for Cher:     artist                           song  \\\n",
      "207   cher            cher_perfection.txt   \n",
      "250   cher  cher_loveandunderstanding.txt   \n",
      "119   cher                cher_mylove.txt   \n",
      "\n",
      "                                        lyrics_content  SentimentScore  \n",
      "207  \"Perfection\"\\n\\n\\n\\nHush little Baby, gotta be...              41  \n",
      "250  \"Love And Understanding\"\\n\\n\\n\\nHere, here in ...              36  \n",
      "119  \"My Love\"\\n\\n\\n\\nWhen I go away\\nI know my hea...              34  \n",
      "\n",
      "Three lowest sentiment songs for Cher:     artist                              song  \\\n",
      "275   cher  cher_iwalkonguildedsplinters.txt   \n",
      "262   cher               cher_outrageous.txt   \n",
      "111   cher                    cher_julie.txt   \n",
      "\n",
      "                                        lyrics_content  SentimentScore  \n",
      "275  \"I Walk On Guilded Splinters\"\\n\\n\\n\\nSome peop...             -25  \n",
      "262  \"Outrageous\"\\n\\n\\n\\nOutrageous, outrageous\\n(T...             -20  \n",
      "111  \"Julie\"\\n\\n\\n\\nCheap lips lie into hungry ears...             -18  \n"
     ]
    }
   ],
   "source": [
    "# first artist, three songs with highest and lowest sentiments\n",
    "\n",
    "first_cher = lyrics_data[lyrics_data['artist'] == 'cher']\n",
    "\n",
    "high_sent_songs = first_cher.nlargest(3, 'SentimentScore') #top 3 highest sentiment songs\n",
    "\n",
    "low_sent_songs = first_cher.nsmallest(3, 'SentimentScore') #3 lowest sentiment songs\n",
    "\n",
    "print(\"Three highest sentiment songs for Cher:\", high_sent_songs)\n",
    "print()\n",
    "print(\"Three lowest sentiment songs for Cher:\", low_sent_songs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1f8334f4",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "Q: Overall, which artist has the higher average sentiment per song? \n",
    "\n",
    "A: Overall, Cher had the higher average sentiment per song.\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your first artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score? \n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: For your second artist, what are the three songs that have the highest and lowest sentiments? Print the lyrics of those songs to the screen. What do you think is driving the sentiment score? \n",
    "\n",
    "A: <!-- Your answer here -->\n",
    "\n",
    "---\n",
    "\n",
    "Q: Plot the distributions of the sentiment scores for both artists. You can use `seaborn` to plot densities or plot histograms in matplotlib.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fe644d",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Twitter Descriptions\n",
    "\n",
    "In this section, define two sets of emojis you designate as positive and negative. Make sure to have at least 10 emojis per set. You can learn about the most popular emojis on Twitter at [the emojitracker](https://emojitracker.com/). \n",
    "\n",
    "Associate your positive emojis with a score of +1, negative with -1. Score the average sentiment of your two artists based on the Twitter descriptions of their followers. The average sentiment can just be the total score divided by number of followers. You do not need to calculate sentiment on non-emoji content for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c1d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb92eb93",
   "metadata": {},
   "source": [
    "Q: What is the average sentiment of your two artists? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n",
    "---\n",
    "\n",
    "Q: Which positive emoji is the most popular for each artist? Which negative emoji? \n",
    "\n",
    "A: <!-- Your answer here --> \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
